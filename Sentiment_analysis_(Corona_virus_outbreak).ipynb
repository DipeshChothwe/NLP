{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis (Corona virus outbreak).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxQu/lWFSSLhs2uOqL9X31",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DipeshChothwe/NLP/blob/master/Sentiment_analysis_(Corona_virus_outbreak).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBYhkmbuPWK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c719cb65-3635-4aa0-a9e2-6cccccd43a13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFMw5r7aLj8b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e03b12f6-5c05-4c5b-e935-13b6aa8835e1"
      },
      "source": [
        "!pip install GetOldTweets3\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: GetOldTweets3 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
            "Requirement already satisfied: pyquery>=1.2.10 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (1.4.1)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na0gfiwFLzeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function for scrapping tweets \n",
        "def get_tweets(date1, date2, tweetname):\n",
        "    import GetOldTweets3 as got   # library used to scrape data from twitter without any other tools\n",
        "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(tweetname) \\\n",
        "        .setSince(date1) \\\n",
        "        .setUntil(date2) \\\n",
        "        .setLang('en') \\\n",
        "        .setMaxTweets(5000)\n",
        "\n",
        "    # Creation of list that contains all tweets\n",
        "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "    # Creating list of chosen tweet data\n",
        "    text_tweets = [[tweet.text] for tweet in tweets]\n",
        "    return text_tweets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewDkLYJbMVjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# scrapping tweets\n",
        "text_before_corona = \"\"\n",
        "text_before_corona_disease = \"\"\n",
        "text_after_corona = \"\"\n",
        "\n",
        "# disease was choosen to get a comparision with pandemic\n",
        "text_tweets_before_corona = get_tweets(\"2019-12-30\", \"2020-01-30\", \"\")\n",
        "text_tweets_before_corona_disease = get_tweets(\"2019-12-30\", \"2020-01-30\", \"disease\")\n",
        "# dates were choosen after WHO officially recognised Corona as pandemic\n",
        "text_tweets_after_corona = get_tweets(\"2020-03-11\", \"2020-04-11\", \"corona\")\n",
        "\n",
        "length1 = len(text_tweets_before_corona)\n",
        "length2 = len(text_tweets_before_corona_disease)\n",
        "length3 = len(text_tweets_after_corona)\n",
        "\n",
        "for i in range(0, length1):\n",
        "    text_before_corona = text_tweets_before_corona[i][0] + \" \" + text_before_corona\n",
        "\n",
        "for i in range(0, length1):\n",
        "    text_before_corona_disease = text_tweets_before_corona_disease[i][0] + \" \" + text_before_corona_disease\n",
        "\n",
        "for i in range(0, length2):\n",
        "    text_after_corona = text_tweets_after_corona[i][0] + \" \" + text_after_corona\n",
        "\n",
        "# converting to lowercase\n",
        "lower_case_before_corona = text_before_corona.lower()\n",
        "lower_case_before_corona_disease = text_before_corona_disease.lower()\n",
        "lower_case_after_corona = text_after_corona.lower()\n",
        "\n",
        "# Removing punctuations\n",
        "cleaned_lower_case_before_corona = lower_case_before_corona.translate(str.maketrans('', '', string.punctuation))\n",
        "cleaned_lower_case_before_corona_disease = lower_case_before_corona_disease.translate(str.maketrans('', '', string.punctuation))\n",
        "cleaned_lower_case_after_corona = lower_case_after_corona.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# splitting text into words\n",
        "tokenized_words_before_corona = cleaned_lower_case_before_corona.split()\n",
        "tokenized_words_before_corona_disease = cleaned_lower_case_before_corona_disease.split()\n",
        "tokenized_words_after_corona = cleaned_lower_case_after_corona.split()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19TxMtFFMbgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print texts\n",
        "#text_tweets_before_corona_disease\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb5XKlpNlnHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#text_tweets_before_corona "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u7FoESCMgXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n",
        "              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\",\n",
        "              \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\",\n",
        "              \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
        "              \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n",
        "              \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
        "              \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
        "              \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
        "              \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
        "\n",
        "# Removing stop words from the tokenized words list\n",
        "final_words_before_corona = [word for word in tokenized_words_before_corona if word not in stop_words]\n",
        "final_words_before_corona_disease = [word for word in tokenized_words_before_corona_disease if word not in stop_words]\n",
        "final_words_after_corona = [word for word in tokenized_words_after_corona if word not in stop_words]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4FxSIzrMlA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0cb3fb58-bf96-4573-a347-5d789efbb7d5"
      },
      "source": [
        "# Get emotions text\n",
        "emotion_list_before_corona = []\n",
        "emotion_list_before_corona_disease = []\n",
        "emotion_list_after_corona = []\n",
        "Word_not_emmotions = {}\n",
        "\n",
        "with open('/content/drive/My Drive/NLP/emotions.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        clear_line = line.replace('\\n', '').replace(',', '').replace(\"'\", '').strip()\n",
        "        word, emotion = clear_line.split(':')\n",
        "        if word in final_words_before_corona:\n",
        "            emotion_list_before_corona.append(emotion)\n",
        "\n",
        "        if word in final_words_before_corona_disease:\n",
        "            emotion_list_before_corona_disease.append(emotion)\n",
        "      \n",
        "        if word in final_words_after_corona:\n",
        "            emotion_list_after_corona.append(emotion)\n",
        "\n",
        "\n",
        "w_before_corona = Counter(emotion_list_before_corona)\n",
        "w_before_corona_disease = Counter(emotion_list_before_corona_disease)\n",
        "w_after_corona = Counter(emotion_list_after_corona)\n",
        "\n",
        "print(\"before corona:\")\n",
        "print(w_before_corona)\n",
        "print(\"before corona serached with disease:\")\n",
        "print(w_before_corona_disease)\n",
        "print(\"after corona:\")\n",
        "print(w_after_corona)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before corona:\n",
            "Counter({' happy': 17, ' fearful': 15, ' sad': 15, ' attracted': 12, ' angry': 11, ' powerless': 9, ' attached': 8, ' adequate': 8, ' cheated': 4, ' alone': 4, ' esteemed': 3, ' embarrassed': 3, ' fearless': 3, ' average': 3, ' surprise': 3, ' obsessed': 3, ' free': 3, ' anxious': 3, ' entitled': 3, ' hated': 3, ' singled out': 2, ' loved': 2, ' focused': 2, ' lustful': 2, ' independent': 2, ' bored': 1, ' safe': 1, ' demoralized': 1, ' ecstatic': 1, ' apathetic': 1, ' lost': 1, ' codependent': 1})\n",
            "before corona serached with disease:\n",
            "Counter({' sad': 20, ' fearful': 19, ' happy': 18, ' attracted': 14, ' powerless': 13, ' angry': 11, ' attached': 10, ' adequate': 8, ' hated': 8, ' anxious': 8, ' esteemed': 5, ' fearless': 5, ' singled out': 5, ' entitled': 5, ' cheated': 4, ' loved': 4, ' codependent': 4, ' alone': 4, ' average': 3, ' surprise': 3, ' focused': 3, ' free': 3, ' embarrassed': 2, ' ecstatic': 2, ' apathetic': 2, ' lost': 2, ' belittled': 1, ' demoralized': 1, ' derailed': 1, ' lustful': 1, ' obsessed': 1, ' safe': 1, ' independent': 1, ' bored': 1})\n",
            "after corona:\n",
            "Counter({' happy': 19, ' sad': 16, ' fearful': 14, ' attracted': 12, ' powerless': 12, ' angry': 9, ' adequate': 6, ' entitled': 6, ' esteemed': 5, ' singled out': 5, ' attached': 5, ' hated': 5, ' alone': 5, ' fearless': 4, ' anxious': 4, ' cheated': 3, ' average': 3, ' apathetic': 3, ' surprise': 3, ' focused': 3, ' ecstatic': 3, ' free': 3, ' codependent': 3, ' loved': 2, ' bored': 2, ' safe': 2, ' lustful': 2, ' demoralized': 1, ' lost': 1, ' obsessed': 1, ' independent': 1, ' embarrassed': 1, ' burdened': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBzQtyymI4cb",
        "colab_type": "text"
      },
      "source": [
        "The Bag of word prediction does not show a significant change in sentiment before or after the pandemic. However this might be because of positive sentiment due to continuosly increasing recovery rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BepFJ-6c2Tux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1ff4c7ad-1c7f-428a-a3f9-5f17d7d12a28"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"vader_lexicon\")\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
        "def sentiment_analyse(sentiment_text):\n",
        "    sid = SIA()\n",
        "    score = sid.polarity_scores(sentiment_text)\n",
        "    \n",
        "    if score['neg'] > score['pos']:\n",
        "        print(\"Negative Sentiment with positive to negative ratio: \", score['pos']/score['neg'])\n",
        "        \n",
        "    elif score['neg'] < score['pos']:\n",
        "        print(\"Positive Sentiment with positive to negative ratio: \", score['pos']/score['neg'])\n",
        "    else:\n",
        "        print(\"Neutral Sentiment\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjVtMTXa2Wkr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cc829d69-661b-4271-8fd5-aaf67b836113"
      },
      "source": [
        "print(\"Sentiment after corona was declared pandemic:\")\n",
        "sentiment_analyse(cleaned_lower_case_after_corona)\n",
        "print(\"Sentiment before corona was declared pandemic searchded with disease tag:\")\n",
        "sentiment_analyse(cleaned_lower_case_before_corona_disease)\n",
        "print(\"Sentiment before corona was declared pandemic:\",)\n",
        "sentiment_analyse(cleaned_lower_case_before_corona)\n",
        "\n",
        "#cleaned_lower_case_before_corona_disease = lower_case_before_corona_disease.translate(str.maketrans('', '', string.punctuation))\n",
        "#cleaned_lower_case_after_corona)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment after corona was declared pandemic:\n",
            "Negative Sentiment with positive to negative ratio:  0.8321678321678322\n",
            "Sentiment before corona was declared pandemic searchded with disease tag:\n",
            "Negative Sentiment with positive to negative ratio:  0.9705882352941176\n",
            "Sentiment before corona was declared pandemic:\n",
            "Positive Sentiment with positive to negative ratio:  1.7339449541284404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CO_k_ZHI_sN",
        "colab_type": "text"
      },
      "source": [
        "Polarity classification with VADER (considering intensity of emotions) model does show decrease in positive sentiment. However, the sentiment is only very slightly negative."
      ]
    }
  ]
}