{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis for world leaders",
      "provenance": [],
      "authorship_tag": "ABX9TyNgXrKN/3bJxJoxq6I63M4t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DipeshChothwe/NLP/blob/master/Sentiment_analysis_for_world_leaders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUNlldTCP1DL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c06be7d-e9ce-4540-d412-53b2a12ad7ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PutwoHVKQdw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "39f98d27-c6f2-47dc-f7fc-b00924a8b840"
      },
      "source": [
        "!pip install GetOldTweets3\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: GetOldTweets3 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
            "Requirement already satisfied: pyquery>=1.2.10 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (1.4.1)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTSI3aHsQUkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function for scrapping tweets \n",
        "\n",
        "def get_tweets(date1, date2, tweetname):\n",
        "    import GetOldTweets3 as got   # library used to scrape data from twitter without any other tools\n",
        "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(tweetname) \\\n",
        "        .setSince(date1) \\\n",
        "        .setUntil(date2) \\\n",
        "        .setLang('en') \\\n",
        "        .setMaxTweets(5000)\n",
        "\n",
        "    # Creation of list that contains all tweets\n",
        "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "    # Creating list of chosen tweet data\n",
        "    text_tweets = [[tweet.text] for tweet in tweets]\n",
        "    return text_tweets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujSbwoZdQJmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining stop words:\n",
        "\n",
        "stop_words = {\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n",
        "              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\",\n",
        "              \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\",\n",
        "              \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
        "              \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n",
        "              \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
        "              \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
        "              \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
        "              \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok59W-jhP55U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing text for Bag of Words:\n",
        "\n",
        "def preprocessing_BOW(list_msgs):\n",
        "  for i in range(0, len(list_msgs)):\n",
        "    text_msgs = list_msgs[i][0] + \" \" + text_msgs\n",
        "  \n",
        "  # 1)Change letters to lowercase; 2)Remove punctuactions; 3)Split sentence in words:\n",
        "  tokanized_words = set(text_msgs.lower().translate(str.maketrans('', '', string.punctuation)).split())\n",
        "\n",
        "  #Tokanization:\n",
        "  tokanized_words_without_stopwords = tokanized_words\n",
        "  tokanized_words_without_stopwords.difference_update(stop_words)\n",
        "\n",
        "  return (tokanized_words_without_stopwords, tokanized_words)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srvsf8oBaKIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PM = [\"@realDonaldTrump\", \"@narendramodi\", \"@JoeBiden\"]\n",
        "\n",
        "tweets_trump = get_tweets(\"2020-07-20\", \"2020-08-20\", \"@realDonaldTrump\")\n",
        "tweets_modi = get_tweets(\"2020-07-20\", \"2020-08-20\", \"@narendramodi\")\n",
        "tweets_joe = get_tweets(\"2020-07-20\", \"2020-08-20\", \"@JoeBiden\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0-W7G9kbjFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get emotions text\n",
        "emotion_list_trump = []\n",
        "emotion_list_modi = []\n",
        "emotion_list_joe = []\n",
        "Word_not_emmotions = []\n",
        "word_to_emotions = {}\n",
        "\n",
        "with open('/content/drive/My Drive/NLP/emotions.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        clear_line = line.replace('\\n', '').replace(',', '').replace(\"'\", '').strip()\n",
        "        word, emotion = clear_line.split(':')\n",
        "        if word in final_words_before_corona:\n",
        "            emotion_list_before_corona.append(emotion)\n",
        "\n",
        "\n",
        "        if word in tweets_trump or tweets_modi or tweets_joe :\n",
        "            emotion_list_before_corona_disease.append(emotion)\n",
        "      \n",
        "        if word in final_words_after_corona:\n",
        "            emotion_list_after_corona.append(emotion)\n",
        "\n",
        "\n",
        "w_before_corona = Counter(emotion_list_before_corona)\n",
        "w_before_corona_disease = Counter(emotion_list_before_corona_disease)\n",
        "w_after_corona = Counter(emotion_list_after_corona)\n",
        "\n",
        "print(\"before corona:\")\n",
        "print(w_before_corona)\n",
        "print(\"before corona serached with disease:\")\n",
        "print(w_before_corona_disease)\n",
        "print(\"after corona:\")\n",
        "print(w_after_corona)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}